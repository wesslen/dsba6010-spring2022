---
date: "2022-01-23"
title: "Class 3"
menu:
  example:
    parent: Examples
weight: 3
toc: true
type: docs
---

<script src="/rmarkdown-libs/clipboard/clipboard.min.js"></script>
<link href="/rmarkdown-libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
<script src="/rmarkdown-libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
<script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
<script src="/rmarkdown-libs/font-awesome/js/script.js"></script>
<a href="data:application/octet-stream;base64,---
date: "`r Sys.Date()`"
title: "Class 3"
menu:
  example:
    parent: Examples
weight: 3
toc: true
type: docs
---

```{r setup, include=FALSE, fig.width=5, fig.height=4}
knitr::opts_chunk$set(echo = TRUE, class.source="language-r", class.output="language-r", message = FALSE, warning = FALSE)
xaringanExtra::use_clipboard()
library(rethinking)
```


```{r echo=FALSE}
downloadthis::download_file(
  path = "03-class.Rmarkdown",
  output_name = "03-class",
  button_label = "Download this code",
  button_type = "danger",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)
```

<a href="https://gitpod.io/#https://github.com/wesslen/dsba6010-examples">
<img align="left" src="https://gitpod.io/button/open-in-gitpod.svg">
</a>

## Introduction

For this class, we'll review code examples found in Chapter 4.

This assumes that you have already installed the `rethinking` package.

If you need help, be sure to remember the references in the [Resources](/resource/):

* [Installing R/RStudio](/resource/install/)
* [Installing `rethinking` package](/resource/install-rethinking/)
* [Rmarkdown](/resource/rmarkdown/)
* [R Style guide](/resource/style/)

## Chapter 4 

### Drawing the Owl

![](../../img/syllabus/owl.png)


### 1. Question or estimand

Objective: Describe the association between Adult **weight** and **height**

```{r}
library(rethinking)
data(Howell1)
d <- Howell1[Howell1$age>=18,]

plot(d$height,d$weight, col = 2, xlab = "height (cm)", ylab = "weight (kg)", lwd=3)
```

Alternatively, using `ggplot2` we can plot the same:

```{r}
library(ggplot2)

ggplot(d, aes(x = height, y = weight)) +
  geom_point(color = "red") +
  labs(x = "height (cm)", y = "weight (kg)") +
  theme_bw()
```


### 2. Scientific model

Weight is a function of height. 

```{r fig.height=1, fig.width=2}
library(dagitty)

g <- dagitty('dag {
    W [pos="0,1"]
    H [pos="1,1"]
    
    W -> H
}')
plot(g)
```

### 3. Statistical model

#### Generative Model

Let's consider the Generative Model (H -> W) from the lecture:

$W_i \sim Normal(\mu_i,\sigma)$<br>
$\mu_i = \alpha + \beta H_i$<br>

```{r}
# forward simulation as we choose these parameters
alpha <- 0 # implies zero height => zero weight
beta <- 0.5 
sigma <- 5
n_individuals <- 100

H <- runif(n_individuals,130,170) # heights, uniform between 130 - 170 cm

mu <- alpha + beta*H
W <- rnorm(n_individuals,mu,sigma) # sample from Normal
```

```{r}
col2 <- col.alpha(2,0.8)
plot(H,W,  col=col2, lwd=3,
     cex=1.2, xlab = "height (cm)", ylab = "weight (kg)")
mtext( "100 Simulated people" )
```
```{r}
# ggplot2 version
df <- data.frame(
  height = H,
  weight = W
)

ggplot(df, aes(x = height, y = weight)) +
  geom_point(color="red") +
  labs(x = "height (cm)", y = "weight (kg)", title = "100 Simulated people")
```

#### Sampling the prior distribution

```{r}
n_samples <- 10

alpha <- rnorm(n_samples,0,1)
beta <- rnorm(n_samples,0,1)

plot(NULL,xlim=c(-2,2),ylim=c(-2,2),xlab="x",ylab="y")
for (i in 1:n_samples){
  abline(alpha[i],beta[i],lwd=4,col=2)
}
```

```{r}
df2 <- data.frame(
  alpha = alpha,
  beta = beta,
  samp = 1:n_samples
)

p <- ggplot(df2) +
  geom_abline(aes(slope = beta, intercept = alpha, group = samp)) +
  xlim(-3,3) +
  ylim(-3,3)

p
```
```{r fig.height=2,fig.width=2}
library(gganimate)

anim <- p + transition_states(samp, transition_length=2, state_length=1) + 
  ggtitle('Sample {closest_state} of 10') +
  enter_fade() +
  exit_fade()

anim
#animate(anim, height=2, width=3)
```

### 3. Statistical model for H->W

```{r}
n <- 10
alpha <- rnorm(n,60,10)
beta <- rnorm(n,0,10)

Hbar <- 150
Hseq <- seq(from=130,to=170,len=30)
plot(NULL, xlim=c(130,170), ylim=c(10,100),
     xlab="height (cm)", ylab="weight (kg)")

for (i in 1:n){
  lines(Hseq, alpha[i] + beta[i]*(Hseq-Hbar),lwd=3,col=2)
}
```
Is this a good prior to be used? Why or why not are they interpretable?

Remember, a lognormal distribution is a distribution that if you take the logarithm of the values, then all of it's values would be normal. 

```{r}
# simulated lognormal
b <- rlnorm(1e4, 0, 1) #4.40
dens(b, xlim=c(0,5), adj=0.1)
```

Let's do a predictive simulation now using the Log-Normal prior.

```{r}
set.seed(2971)
N <- 100  
a <- rnorm( N , 60 , 10 )
b <- rlnorm( N , 0 , 1 )

plot(NULL, xlim=c(130,170), ylim=c(10,100),
     xlab="height (cm)", ylab="weight (kg)")

for (i in 1:n){
  lines(Hseq, a[i] + b[i]*(Hseq-Hbar),lwd=3,col=2)
}
```
{{% callout note %}}

Key is justify priors with information outside of the data (that will be modeled). This is similar to machine learning where we don't want to include records in our test dataset that were also in our training. Using modeled data to form priors can be thought of as "prior-hacking". Typically in literature, Bayesian approaches require pre-registration when using non-informative priors (see [this example from Fernandes et al., 2018](https://github.com/michael-fernandes/uncertainty-displays-for-transit/blob/master/pre-registration.pdf)).

{{% /callout %}}

$W_i \sim Normal(\mu_i,\sigma)$<br>
$\mu_i = \alpha + \beta(H_i - \overline{H})$<br>
$\alpha \sim Normal(60,10)$<br>
$\beta \sim LogNormal(0,1)$<br>
$\sigma \sim Uniform(0,10)$<br>

```{r}
# define the average weight, x-bar
xbar <- mean(d$weight)

# fit model
m4.3 <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- a + b*( weight - xbar ) ,
        a ~ dnorm( 178 , 20 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d )

## R code 4.43
m4.3b <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- a + exp(log_b)*( weight - xbar ),
        a ~ dnorm( 178 , 20 ) ,
        log_b ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d )

## R code 4.44
precis( m4.3 )
```

```{r}
## R code 4.45
round( vcov( m4.3 ) , 3 )
```

### 4. Validate model

We'll use a **simulation-based** validation.

We'll first validate with a simulation (aka fake data).

```{r}
alpha <- 70
beta <- 0.5
sigma <- 5
n_individuals <- 100
H <- runif(n_individuals,130,170)
mu <- alpha + beta*(H-mean(H))
W <- rnorm(n_individuals,mu,sigma)

dat <- list(H=H,W=W,Hbar=mean(H))

m_validate <- quap(
    alist(
        W ~ dnorm( mu , sigma ) ,
        mu <- a + b*( H - Hbar ),
        a ~ dnorm( 60 , 10 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) , data=dat )

precis(m_validate)
```

```{r}
dat <- list(W = d$weight, H = d$height, Hbar = mean(d$height))

m_adults <- quap(
    alist(
        W ~ dnorm( mu , sigma ) ,
        mu <- a + b*( H - Hbar ),
        a ~ dnorm( 60 , 10 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) , data=dat )

precis(m_adults)
```

{{% callout note %}}

First Law of Statistical Interpretation: The **parameters are not independent** of one another and cannot always be independently interpreted.

Instead, draw (push out) **posterior predictions** and describe/interpret them.

{{% /callout %}}

```{r}
post <- extract.samples(m_adults)
head(post)
```

#### 1. Plot the sample

```{r}
# 4.4.3
col2 <- col.alpha(2,0.8)
plot(d$height, d$weight, col=col2, lwd=3,
     cex=1.2, xlab="height (cm)", ylab="weight (kg)")
```

#### 2. Plot the posterior mean


```{r}
weight.seq <- seq(from=25,to=70,by=1)
mu <- link(m4.3,data=list(weight=weight.seq))
plot(d$height,d$weight,  col=col2, lwd=3,
     cex=1.2, xlab="height (cm)", ylab="weight (kg)")
lines(  apply(mu,2,mean), weight.seq, lwd=4)
```

#### 3. Plot uncertainty of the mean

```{r}
xseq <- seq(from=130,to=190,len=50)
plot(d$height, d$weight, col=col2, lwd=3,
     cex=1.2, xlab="height (cm)", ylab="weight (kg)")
lines(   apply(mu,2,mean), weight.seq,lwd=4)
shade( apply(mu,2,PI,prob=0.99), weight.seq, col=col.alpha(2,0.5))
```

#### 4. Plot uncertainty of predictions

{{% callout note %}}

Try as [challenging exercise as shown in Slide 70 of Lecture 3](https://speakerdeck.com/rmcelreath/statistical-rethinking-2022-lecture-03?slide=70).

{{% /callout %}}

## Package versions

```{r}
sessionInfo()
```" download="03-class.Rmarkdown">
<button class="btn btn-danger"><i class="fa fa-save"></i> Download this code</button>
</a>

<a href="https://gitpod.io/#https://github.com/wesslen/dsba6010-examples">
<img align="left" src="https://gitpod.io/button/open-in-gitpod.svg">
</a>

## Introduction

For this class, we’ll review code examples found in Chapter 4.

This assumes that you have already installed the `rethinking` package.

If you need help, be sure to remember the references in the [Resources](/resource/):

-   [Installing R/RStudio](/resource/install/)
-   [Installing `rethinking` package](/resource/install-rethinking/)
-   [Rmarkdown](/resource/rmarkdown/)
-   [R Style guide](/resource/style/)

## Chapter 4

### Drawing the Owl

![](../../img/syllabus/owl.png)

### 1. Question or estimand

Objective: Describe the association between Adult **weight** and **height**

``` r
library(rethinking)
data(Howell1)
d <- Howell1[Howell1$age>=18,]

plot(d$height,d$weight, col = 2, xlab = "height (cm)", ylab = "weight (kg)", lwd=3)
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-2-1.png" width="672" />

Alternatively, using `ggplot2` we can plot the same:

``` r
library(ggplot2)

ggplot(d, aes(x = height, y = weight)) +
  geom_point(color = "red") +
  labs(x = "height (cm)", y = "weight (kg)") +
  theme_bw()
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-3-1.png" width="672" />

### 2. Scientific model

Weight is a function of height.

``` r
library(dagitty)

g <- dagitty('dag {
    W [pos="0,1"]
    H [pos="1,1"]
    
    W -> H
}')
plot(g)
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-4-1.png" width="192" />

### 3. Statistical model

#### Generative Model

Let’s consider the Generative Model (H -&gt; W) from the lecture:

`\(W_i \sim Normal(\mu_i,\sigma)\)`<br>
`\(\mu_i = \alpha + \beta H_i\)`<br>

``` r
# forward simulation as we choose these parameters
alpha <- 0 # implies zero height => zero weight
beta <- 0.5 
sigma <- 5
n_individuals <- 100

H <- runif(n_individuals,130,170) # heights, uniform between 130 - 170 cm

mu <- alpha + beta*H
W <- rnorm(n_individuals,mu,sigma) # sample from Normal
```

``` r
col2 <- col.alpha(2,0.8)
plot(H,W,  col=col2, lwd=3,
     cex=1.2, xlab = "height (cm)", ylab = "weight (kg)")
mtext( "100 Simulated people" )
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-6-1.png" width="672" />

``` r
# ggplot2 version
df <- data.frame(
  height = H,
  weight = W
)

ggplot(df, aes(x = height, y = weight)) +
  geom_point(color="red") +
  labs(x = "height (cm)", y = "weight (kg)", title = "100 Simulated people")
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-7-1.png" width="672" />

#### Sampling the prior distribution

``` r
n_samples <- 10

alpha <- rnorm(n_samples,0,1)
beta <- rnorm(n_samples,0,1)

plot(NULL,xlim=c(-2,2),ylim=c(-2,2),xlab="x",ylab="y")
for (i in 1:n_samples){
  abline(alpha[i],beta[i],lwd=4,col=2)
}
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-8-1.png" width="672" />

``` r
df2 <- data.frame(
  alpha = alpha,
  beta = beta,
  samp = 1:n_samples
)

p <- ggplot(df2) +
  geom_abline(aes(slope = beta, intercept = alpha, group = samp)) +
  xlim(-3,3) +
  ylim(-3,3)

p
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-9-1.png" width="672" />

``` r
library(gganimate)

anim <- p + transition_states(samp, transition_length=2, state_length=1) + 
  ggtitle('Sample {closest_state} of 10') +
  enter_fade() +
  exit_fade()

anim
```

![](03-class_files/figure-html/unnamed-chunk-10-1.gif)<!-- -->

``` r
#animate(anim, height=2, width=3)
```

### 3. Statistical model for H-&gt;W

``` r
n <- 10
alpha <- rnorm(n,60,10)
beta <- rnorm(n,0,10)

Hbar <- 150
Hseq <- seq(from=130,to=170,len=30)
plot(NULL, xlim=c(130,170), ylim=c(10,100),
     xlab="height (cm)", ylab="weight (kg)")

for (i in 1:n){
  lines(Hseq, alpha[i] + beta[i]*(Hseq-Hbar),lwd=3,col=2)
}
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-11-1.png" width="672" />
Is this a good prior to be used? Why or why not are they interpretable?

Remember, a lognormal distribution is a distribution that if you take the logarithm of the values, then all of it’s values would be normal.

``` r
# simulated lognormal
b <- rlnorm(1e4, 0, 1) #4.40
dens(b, xlim=c(0,5), adj=0.1)
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-12-1.png" width="672" />

Let’s do a predictive simulation now using the Log-Normal prior.

``` r
set.seed(2971)
N <- 100  
a <- rnorm( N , 60 , 10 )
b <- rlnorm( N , 0 , 1 )

plot(NULL, xlim=c(130,170), ylim=c(10,100),
     xlab="height (cm)", ylab="weight (kg)")

for (i in 1:n){
  lines(Hseq, a[i] + b[i]*(Hseq-Hbar),lwd=3,col=2)
}
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-13-1.png" width="672" />
{{% callout note %}}

Key is justify priors with information outside of the data (that will be modeled). This is similar to machine learning where we don’t want to include records in our test dataset that were also in our training. Using modeled data to form priors can be thought of as “prior-hacking.” Typically in literature, Bayesian approaches require pre-registration when using non-informative priors (see [this example from Fernandes et al., 2018](https://github.com/michael-fernandes/uncertainty-displays-for-transit/blob/master/pre-registration.pdf)).

{{% /callout %}}

`\(W_i \sim Normal(\mu_i,\sigma)\)`<br>
`\(\mu_i = \alpha + \beta(H_i - \overline{H})\)`<br>
`\(\alpha \sim Normal(60,10)\)`<br>
`\(\beta \sim LogNormal(0,1)\)`<br>
`\(\sigma \sim Uniform(0,10)\)`<br>

``` r
# define the average weight, x-bar
xbar <- mean(d$weight)

# fit model
m4.3 <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- a + b*( weight - xbar ) ,
        a ~ dnorm( 178 , 20 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d )

## R code 4.43
m4.3b <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- a + exp(log_b)*( weight - xbar ),
        a ~ dnorm( 178 , 20 ) ,
        log_b ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d )

## R code 4.44
precis( m4.3 )
```

``` language-r
##              mean         sd        5.5%       94.5%
## a     154.6013671 0.27030766 154.1693633 155.0333710
## b       0.9032807 0.04192363   0.8362787   0.9702828
## sigma   5.0718809 0.19115478   4.7663786   5.3773831
```

``` r
## R code 4.45
round( vcov( m4.3 ) , 3 )
```

``` language-r
##           a     b sigma
## a     0.073 0.000 0.000
## b     0.000 0.002 0.000
## sigma 0.000 0.000 0.037
```

### 4. Validate model

We’ll use a **simulation-based** validation.

We’ll first validate with a simulation (aka fake data).

``` r
alpha <- 70
beta <- 0.5
sigma <- 5
n_individuals <- 100
H <- runif(n_individuals,130,170)
mu <- alpha + beta*(H-mean(H))
W <- rnorm(n_individuals,mu,sigma)

dat <- list(H=H,W=W,Hbar=mean(H))

m_validate <- quap(
    alist(
        W ~ dnorm( mu , sigma ) ,
        mu <- a + b*( H - Hbar ),
        a ~ dnorm( 60 , 10 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) , data=dat )

precis(m_validate)
```

``` language-r
##             mean         sd       5.5%      94.5%
## a     69.0995550 0.54004359 68.2364610 69.9626489
## b      0.4964795 0.04541645  0.4238952  0.5690637
## sigma  5.4081970 0.38242915  4.7970013  6.0193926
```

``` r
dat <- list(W = d$weight, H = d$height, Hbar = mean(d$height))

m_adults <- quap(
    alist(
        W ~ dnorm( mu , sigma ) ,
        mu <- a + b*( H - Hbar ),
        a ~ dnorm( 60 , 10 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
    ) , data=dat )

precis(m_adults)
```

``` language-r
##             mean         sd       5.5%      94.5%
## a     44.9981095 0.22538649 44.6378984 45.3583207
## b      0.6286963 0.02914519  0.5821166  0.6752759
## sigma  4.2296862 0.15941301  3.9749134  4.4844589
```

{{% callout note %}}

First Law of Statistical Interpretation: The **parameters are not independent** of one another and cannot always be independently interpreted.

Instead, draw (push out) **posterior predictions** and describe/interpret them.

{{% /callout %}}

``` r
post <- extract.samples(m_adults)
head(post)
```

``` language-r
##          a         b    sigma
## 1 44.82069 0.6653022 4.255300
## 2 44.61808 0.6124963 4.308619
## 3 44.98197 0.6448394 4.330455
## 4 45.04989 0.6703432 4.207164
## 5 45.01499 0.5998628 4.345470
## 6 44.84421 0.6480714 4.360352
```

#### 1. Plot the sample

``` r
# 4.4.3
col2 <- col.alpha(2,0.8)
plot(d$height, d$weight, col=col2, lwd=3,
     cex=1.2, xlab="height (cm)", ylab="weight (kg)")
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-19-1.png" width="672" />

#### 2. Plot the posterior mean

``` r
weight.seq <- seq(from=25,to=70,by=1)
mu <- link(m4.3,data=list(weight=weight.seq))
plot(d$height,d$weight,  col=col2, lwd=3,
     cex=1.2, xlab="height (cm)", ylab="weight (kg)")
lines(  apply(mu,2,mean), weight.seq, lwd=4)
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-20-1.png" width="672" />

#### 3. Plot uncertainty of the mean

``` r
xseq <- seq(from=130,to=190,len=50)
plot(d$height, d$weight, col=col2, lwd=3,
     cex=1.2, xlab="height (cm)", ylab="weight (kg)")
lines(   apply(mu,2,mean), weight.seq,lwd=4)
shade( apply(mu,2,PI,prob=0.99), weight.seq, col=col.alpha(2,0.5))
```

<img src="/example/03-class_files/figure-html/unnamed-chunk-21-1.png" width="672" />

#### 4. Plot uncertainty of predictions

{{% callout note %}}

Try as [challenging exercise as shown in Slide 70 of Lecture 3](https://speakerdeck.com/rmcelreath/statistical-rethinking-2022-lecture-03?slide=70).

{{% /callout %}}

## Package versions

``` r
sessionInfo()
```

``` language-r
## R version 4.1.1 (2021-08-10)
## Platform: aarch64-apple-darwin20 (64-bit)
## Running under: macOS Monterey 12.1
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices datasets  utils     methods  
## [8] base     
## 
## other attached packages:
## [1] gganimate_1.0.7      dagitty_0.3-1        rethinking_2.21     
## [4] cmdstanr_0.4.0.9001  rstan_2.21.3         ggplot2_3.3.5       
## [7] StanHeaders_2.21.0-7
## 
## loaded via a namespace (and not attached):
##  [1] matrixStats_0.61.0   fs_1.5.0             lubridate_1.8.0     
##  [4] progress_1.2.2       tensorA_0.36.2       tools_4.1.1         
##  [7] backports_1.4.1      bslib_0.3.1          utf8_1.2.2          
## [10] R6_2.5.1             DBI_1.1.1            colorspace_2.0-2    
## [13] withr_2.4.3          tidyselect_1.1.1     gridExtra_2.3       
## [16] prettyunits_1.1.1    processx_3.5.2       curl_4.3.2          
## [19] compiler_4.1.1       cli_3.1.0            labeling_0.4.2      
## [22] bookdown_0.24        posterior_1.1.0      sass_0.4.0          
## [25] scales_1.1.1         checkmate_2.0.0      mvtnorm_1.1-3       
## [28] callr_3.7.0          bsplus_0.1.3         stringr_1.4.0       
## [31] digest_0.6.29        rmarkdown_2.11       base64enc_0.1-3     
## [34] pkgconfig_2.0.3      htmltools_0.5.2      fastmap_1.1.0       
## [37] highr_0.9            rlang_0.4.12         rstudioapi_0.13     
## [40] shape_1.4.6          jquerylib_0.1.4      farver_2.1.0        
## [43] generics_0.1.1       jsonlite_1.7.2       dplyr_1.0.7         
## [46] distributional_0.2.2 inline_0.3.19        magrittr_2.0.1      
## [49] loo_2.4.1            Rcpp_1.0.7           munsell_0.5.0       
## [52] fansi_0.5.0          abind_1.4-5          lifecycle_1.0.1     
## [55] stringi_1.7.6        yaml_2.2.1           MASS_7.3-54         
## [58] plyr_1.8.6           pkgbuild_1.3.1       grid_4.1.1          
## [61] crayon_1.4.2         lattice_0.20-44      hms_1.1.1           
## [64] magick_2.7.3         knitr_1.36           ps_1.6.0            
## [67] pillar_1.6.4         uuid_1.0-3           boot_1.3-28         
## [70] codetools_0.2-18     stats4_4.1.1         glue_1.6.0          
## [73] evaluate_0.14        blogdown_1.5         V8_3.6.0            
## [76] renv_0.14.0          RcppParallel_5.1.4   tweenr_1.0.2        
## [79] vctrs_0.3.8          gtable_0.3.0         purrr_0.3.4         
## [82] assertthat_0.2.1     xfun_0.28            mime_0.12           
## [85] coda_0.19-4          tibble_3.1.6         ellipsis_0.3.2      
## [88] downloadthis_0.2.1   xaringanExtra_0.5.5
```
