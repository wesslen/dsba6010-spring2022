---
date: "2022-01-10"
linkTitle: Syllabus
summary: Bayesian statistics and causal inference
title: "\U0001F4CA Syllabus"
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<!-- {{< tweet 1329573633371631617 >}}-->
<div id="what-you-will-learn" class="section level2">
<h2>What you will learn</h2>
<ul>
<li>Bayesian inference through <strong>probabilistic programming</strong> (R/Stan, Python/PyMC3, Julia/Turing.jl)</li>
<li><strong>Computational approaches</strong> for statistical modeling (e.g., quadratic approximation, sampling, MCMC, Hamiltonian Monte Carlo)</li>
<li>Techniques from machine learning to <strong>reduce overfitting</strong> in statistical models (e.g., cross-validation, regularization, shrinkage, pooling)</li>
<li><strong>Causal inference</strong> to develop robust statistical models and identify causal relationships</li>
</ul>
</div>
<div id="course-overview" class="section level2">
<h2>Course overview</h2>
<p>This course builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today’s model-based statistics, students will perform step-by-step calculations that are usually automated. This unique computational approach ensures that sufficient understanding to make reasonable choices and interpretations in your own modeling work.</p>
<p>We’ll cover causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. If time, we’ll discuss measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.</p>
<p>The course also includes directed acyclic graph (DAG) approach to causal inference. Additional topics may include the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. Our goal is to go beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.</p>
<p>Application of the models will focus on research in cognitive science, human-computer interaction, computational social science, and information visualization.</p>
</div>
<div id="faqs" class="section level2">
<h2>FAQs</h2>
<p>{{% spoiler text="What are the course prerequisites?" %}}</p>
<p><strong>Programming</strong>: Experience with R (e.g., installing packages, loading data, RStudio). Students without should immediately consider DataCamp courses and hands-on practice problems.</p>
<p><strong>Probability</strong>: Fundamental probability theory is highly recommended. This includes exposure to common distributions like Normal (Gaussian), Binomial, and Beta distributions.</p>
<p>We’ll also assume core understanding of statistical models like linear regression.</p>
<p>{{% /spoiler %}}{{% spoiler text="What programming languages will be used?" %}}</p>
<ul>
<li><p>Lectures and coursework will use R. Students must complete assignments in R and the mid-term may cover some R code examples.</p></li>
<li><p>Final projects can be done in Python (e.g., pyMC3) or Julia (turing.jl); however, it is the student’s responsibility to be fluent in setting up related environments/packages (e.g., Jupyter, virtual environments, etc.) if they want to use Python or Julia.</p></li>
</ul>
</div>
